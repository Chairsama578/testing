import streamlit as st
import os
import random
from PIL import Image
import numpy as np
import tensorflow as tf
import joblib


# ==============================
#  üîß CONFIG
# ==============================
DATA_DIR = "images_raw"
MODEL_DIR = "models/waste_model"
LABEL_FILE = "models/labels.pkl"


# ==============================
#  üî∂ STYLE BOX
# ==============================
def yellow_box(text: str):
    st.markdown(
        f"""
        <div style="
            background-color:#fff7cc;
            padding:18px;
            border-radius:10px;
            border:1px solid #e6d784;
            font-size:17px;
            line-height:1.6;">
            {text}
        </div>
        """,
        unsafe_allow_html=True,
    )


# ==============================
#  üî∂ LOAD MODEL + LABELS
# ==============================
@st.cache_resource
def load_infer_and_labels():
    if not os.path.exists(MODEL_DIR):
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y SavedModel trong th∆∞ m·ª•c models/waste_model.")
        st.stop()

    model = tf.saved_model.load(MODEL_DIR)
    infer_fn = model.signatures["serving_default"]

    if not os.path.exists(LABEL_FILE):
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y models/labels.pkl.")
        st.stop()

    labels = joblib.load(LABEL_FILE)
    return infer_fn, labels


infer, LABELS = load_infer_and_labels()


def predict_path(img_path: str):
    """D·ª± ƒëo√°n 1 ·∫£nh theo ƒë∆∞·ªùng d·∫´n (d√πng cho ph·∫ßn ƒë√°nh gi√°)."""

    img = Image.open(img_path).convert("RGB")
    img = img.resize((224, 224))

    arr = np.array(img, dtype=np.uint8)
    arr = np.expand_dims(arr, axis=0)
    tensor = tf.convert_to_tensor(arr, dtype=tf.uint8)

    out = infer(tensor)
    probs = list(out.values())[0].numpy()[0]

    idx = int(np.argmax(probs))
    conf = float(probs[idx])

    return LABELS[idx], conf


# ==============================
#  üî∂ PAGE
# ==============================
def show():
    st.markdown(
        "<h2 style='color:#2b6f3e;'>Training Info ‚Äì Th√¥ng tin hu·∫•n luy·ªán AutoKeras</h2>",
        unsafe_allow_html=True,
    )

    # -------------------------------------------------------
    # 1. Hi·ªán d·ªØ li·ªáu th√¥
    # -------------------------------------------------------
    yellow_box(
        """
        <h3 style="color:#b30000;">1. Hi·ªán d·ªØ li·ªáu th√¥</h3>
        Dataset g·ªëc ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c <b>images_raw/</b>, g·ªìm c√°c l·ªõp:
        <code>glass, metal, organic, others, paper, plastic</code>.
        H·ªá th·ªëng s·∫Ω th·ªëng k√™ s·ªë l∆∞·ª£ng ·∫£nh ban ƒë·∫ßu c·ªßa t·ª´ng l·ªõp.
        """
    )

    if not os.path.exists(DATA_DIR):
        st.error("‚ö† Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c images_raw/.")
        return

    raw_stats = {}
    classes = sorted(
        [c for c in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, c))]
    )

    for cls in classes:
        folder = os.path.join(DATA_DIR, cls)
        files = [
            f
            for f in os.listdir(folder)
            if f.lower().endswith((".jpg", ".jpeg", ".png"))
            and not f.startswith("aug_")
        ]
        raw_stats[cls] = len(files)

    st.write("**üìä S·ªë l∆∞·ª£ng ·∫£nh g·ªëc (ch∆∞a augment):**")
    st.table({"L·ªõp": list(raw_stats.keys()), "S·ªë ·∫£nh g·ªëc": list(raw_stats.values())})

    st.write("---")

    # -------------------------------------------------------
    # 2. Hi·ªán x·ª≠ l√Ω d·ªØ li·ªáu th√¥ ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu)
    # -------------------------------------------------------
    yellow_box(
        """
        <h3 style="color:#b30000;">2. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu & Augmentation</h3>
        C√°c ·∫£nh ƒë∆∞·ª£c <b>resize v·ªÅ 224√ó224</b> v√† l∆∞u th√™m c√°c phi√™n b·∫£n augment
        (xoay, l·∫≠t, thay ƒë·ªïi ƒë·ªô s√°ng, th√™m nhi·ªÖu, ...). C√°c ·∫£nh augment ƒë∆∞·ª£c ƒë·∫∑t
        t√™n b·∫Øt ƒë·∫ßu b·∫±ng <code>aug_*.jpg</code>.
        """
    )

    aug_stats = {}
    total_stats = {}

    for cls in classes:
        folder = os.path.join(DATA_DIR, cls)
        all_imgs = [
            f
            for f in os.listdir(folder)
            if f.lower().endswith((".jpg", ".jpeg", ".png"))
        ]
        aug_imgs = [f for f in all_imgs if f.startswith("aug_")]
        aug_stats[cls] = len(aug_imgs)
        total_stats[cls] = len(all_imgs)

    st.write("**üìä S·ªë l∆∞·ª£ng ·∫£nh sau khi augment:**")
    st.table(
        {
            "L·ªõp": classes,
            "·∫¢nh g·ªëc": [raw_stats.get(c, 0) for c in classes],
            "·∫¢nh augment (aug_*)": [aug_stats.get(c, 0) for c in classes],
            "T·ªïng ·∫£nh": [total_stats.get(c, 0) for c in classes],
        }
    )

    st.write("---")

    # -------------------------------------------------------
    # 3. Hi·ªán ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi l∆∞u model
    # -------------------------------------------------------
    yellow_box(
        """
        <h3 style="color:#b30000;">3. ƒê∆∞·ªùng d·∫´n l∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán</h3>
        M√¥ h√¨nh t·ªët nh·∫•t do AutoKeras ch·ªçn ƒë∆∞·ª£c export theo ƒë·ªãnh d·∫°ng
        <b>SavedModel</b> v√† l∆∞u t·∫°i:
        """
    )

    st.code(
        f"""
models/
    waste_model/      # SavedModel (export t·ª´ AutoKeras)
        saved_model.pb
        variables/
        assets/
    labels.pkl        # Danh s√°ch nh√£n theo th·ª© t·ª± index softmax
""",
        language="text",
    )

    st.write("---")

    # -------------------------------------------------------
    # 4. ƒê·ªçc th√¥ng tin model object
    # -------------------------------------------------------
    yellow_box(
        """
        <h3 style="color:#b30000;">4. Th√¥ng tin v·ªÅ m√¥ h√¨nh SavedModel</h3>
        D∆∞·ªõi ƒë√¢y l√† th√¥ng tin input/output c·ªßa signature
        <code>serving_default</code> trong SavedModel, d√πng cho vi·ªác suy lu·∫≠n
        (inference) trong ·ª©ng d·ª•ng.
        """
    )

    st.write("**üì• Input signature:**")
    st.code(str(infer.structured_input_signature), language="text")

    st.write("**üì§ Output signature:**")
    st.code(str(infer.structured_outputs), language="text")

    # -------------------------------------------------------
    # 5‚Äì7. K·∫øt qu·∫£ train & ƒë√°nh gi√° ƒë·ªô tin c·∫≠y (ƒë√°nh gi√° nhanh tr√™n dataset)
    # -------------------------------------------------------
    yellow_box(
        """
        <h3 style="color:#b30000;">5‚Äì7. K·∫øt qu·∫£ train & ƒê√°nh gi√° ƒë·ªô tin c·∫≠y m√¥ h√¨nh</h3>
        ƒê·ªÉ minh h·ªça, h·ªá th·ªëng s·∫Ω ch·∫°y <b>ƒë√°nh gi√° nhanh</b> tr√™n to√†n b·ªô
        dataset hi·ªán c√≥ (g·ªìm c·∫£ ·∫£nh g·ªëc v√† ·∫£nh augment) v√† t√≠nh:
        <ul>
            <li>ƒê·ªô ch√≠nh x√°c (accuracy) theo t·ª´ng l·ªõp v√† to√†n b·ªô.</li>
            <li>ƒê·ªô tin c·∫≠y trung b√¨nh (mean confidence) c·ªßa c√°c d·ª± ƒëo√°n ƒë√∫ng.</li>
        </ul>
        L∆∞u √Ω: ƒë√¢y ch·ªâ l√† ƒë√°nh gi√° tham kh·∫£o, kh√¥ng thay th·∫ø cho ƒë√°nh gi√° tr√™n
        t·∫≠p ki·ªÉm tra ƒë·ªôc l·∫≠p.
        """
    )

    if st.button("‚ñ∂ Ch·∫°y ƒë√°nh gi√° nhanh tr√™n dataset"):
        per_class_total = {c: 0 for c in classes}
        per_class_correct = {c: 0 for c in classes}
        per_class_conf_sum = {c: 0.0 for c in classes}

        image_paths = []

        for cls in classes:
            folder = os.path.join(DATA_DIR, cls)
            files = [
                f
                for f in os.listdir(folder)
                if f.lower().endswith((".jpg", ".jpeg", ".png"))
            ]
            for f in files:
                image_paths.append((cls, os.path.join(folder, f)))

        progress = st.progress(0.0)
        n = len(image_paths)

        for i, (true_cls, path) in enumerate(image_paths, start=1):
            pred_cls, conf = predict_path(path)

            per_class_total[true_cls] += 1
            if pred_cls == true_cls:
                per_class_correct[true_cls] += 1
                per_class_conf_sum[true_cls] += conf

            progress.progress(i / n)

        # T√≠nh b·∫£ng k·∫øt qu·∫£
        rows = []
        total_correct = 0
        total_images = 0

        for cls in classes:
            total = per_class_total[cls]
            correct = per_class_correct[cls]
            acc = correct / total * 100 if total > 0 else 0.0
            mean_conf = per_class_conf_sum[cls] / correct if correct > 0 else 0.0

            rows.append(
                {
                    "L·ªõp": cls,
                    "S·ªë ·∫£nh": total,
                    "D·ª± ƒëo√°n ƒë√∫ng": correct,
                    "Accuracy (%)": round(acc, 2),
                    "Mean confidence (ƒë√∫ng)": round(mean_conf, 4),
                }
            )

            total_correct += correct
            total_images += total

        st.write("**üìä K·∫øt qu·∫£ theo t·ª´ng l·ªõp:**")
        st.dataframe(rows, hide_index=True)

        if total_images > 0:
            overall_acc = total_correct / total_images * 100
            st.success(
                f"üéØ ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ tr√™n to√†n b·ªô dataset: **{overall_acc:.2f}%**"
            )

    st.write("---")

    # -------------------------------------------------------
    # 8. G·ª£i √Ω so s√°nh v·ªõi c√°c m√¥ h√¨nh kh√°c
    # -------------------------------------------------------
    yellow_box(
        """
        <h3 style="color:#b30000;">8. So s√°nh k·∫øt qu·∫£ v·ªõi c√°c m√¥ h√¨nh kh√°c</h3>
        Trong ƒë·ªÅ t√†i n√†y, AutoKeras ƒë√£ t·ª± ƒë·ªông th·ª≠ nhi·ªÅu ki·∫øn tr√∫c CNN kh√°c nhau
        (ResNet, Xception, v.v.) v√† ch·ªçn ra m√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c cao nh·∫•t.
        <br><br>
        ƒê·ªÉ m·ªü r·ªông, sinh vi√™n c√≥ th·ªÉ:
        <ul>
            <li><b>8.1 Hu·∫•n luy·ªán th√™m m·ªôt m√¥ h√¨nh th·ªß c√¥ng</b> (v√≠ d·ª•: CNN thu·∫ßn Keras).</li>
            <li><b>8.2 So s√°nh accuracy, th·ªùi gian train, k√≠ch th∆∞·ªõc m√¥ h√¨nh</b> gi·ªØa AutoKeras v√† CNN th·ªß c√¥ng.</li>
        </ul>
        """
    )

    # 8.1 ‚Äì V√≠ d·ª• code CNN thu·∫ßn Keras
    st.markdown("### 8.1 Hu·∫•n luy·ªán th√™m m·ªôt m√¥ h√¨nh CNN thu·∫ßn Keras (minh ho·∫°)")

    with st.expander("üìå Xem v√≠ d·ª• code CNN thu·∫ßn Keras"):
        st.code(
            """
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

IMG_SIZE = (224, 224)
NUM_CLASSES = 6  # glass, metal, organic, others, paper, plastic

# 1. Load ·∫£nh th√†nh numpy array (X) v√† nh√£n (y) gi·ªëng ph·∫ßn train_autokeras.py
#    Gi·∫£ s·ª≠ ƒë√£ c√≥ X.shape = (N, 224, 224, 3), y l√† nh√£n d·∫°ng s·ªë 0..5

# 2. Chu·∫©n ho√°
X = X.astype("float32") / 255.0

# 3. X√¢y d·ª±ng CNN ƒë∆°n gi·∫£n
model = keras.Sequential([
    layers.Input(shape=(*IMG_SIZE, 3)),
    layers.Conv2D(32, 3, activation="relu"),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation="relu"),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation="relu"),
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation="relu"),
    layers.Dense(NUM_CLASSES, activation="softmax")
])

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)

# 4. Train m√¥ h√¨nh
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=32
)

# 5. L∆∞u model ƒë·ªÉ so s√°nh k√≠ch th∆∞·ªõc v·ªõi AutoKeras
model.save("models/manual_cnn.keras")  # ho·∫∑c .h5
            """,
            language="python",
        )

    st.markdown(
        """
        üëâ Sinh vi√™n c√≥ th·ªÉ copy ƒëo·∫°n code tr√™n ra file ri√™ng
        (v√≠ d·ª• <code>train_cnn_manual.py</code>), ch·ªânh s·ª≠a l·∫°i ph·∫ßn ƒë·ªçc d·ªØ li·ªáu
        gi·ªëng v·ªõi <code>train_autokeras.py</code> v√† ch·∫°y ƒë·ªÉ thu ƒë∆∞·ª£c:
        <ul>
            <li>Accuracy tr√™n t·∫≠p validation/test.</li>
            <li>Th·ªùi gian hu·∫•n luy·ªán (t·ªïng th·ªùi gian ch·∫°y script).</li>
            <li>K√≠ch th∆∞·ªõc file m√¥ h√¨nh <code>manual_cnn.keras</code>.</li>
        </ul>
        """
    )

    # 8.2 ‚Äì B·∫£ng khung so s√°nh
    st.markdown("### 8.2 Khung so s√°nh AutoKeras vs CNN thu·∫ßn Keras")

    st.write(
        """
        Sau khi hu·∫•n luy·ªán xong c·∫£ hai m√¥ h√¨nh, sinh vi√™n ghi l·∫°i c√°c s·ªë li·ªáu
        (accuracy, th·ªùi gian train, k√≠ch th∆∞·ªõc file) v√† ƒëi·ªÅn v√†o b·∫£ng d∆∞·ªõi ƒë√¢y
        trong b√°o c√°o. ·ªû ·ª©ng d·ª•ng demo, b·∫£ng ch·ªâ mang t√≠nh minh h·ªça.
        """
    )

    # B·∫£ng khung (sinh vi√™n t·ª± c·∫≠p nh·∫≠t s·ªë li·ªáu th·∫≠t trong b√°o c√°o)
    st.table(
        {
            "M√¥ h√¨nh": ["AutoKeras ImageClassifier", "CNN thu·∫ßn Keras"],
            "Accuracy tr√™n t·∫≠p ƒë√°nh gi√° (%)": ["...", "..."],
            "Th·ªùi gian train (ph√∫t)": ["...", "..."],
            "K√≠ch th∆∞·ªõc file model (MB)": ["...", "..."],
        }
    )
